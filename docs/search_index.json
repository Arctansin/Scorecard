[["index.html", "Financial Scorecard Chapter 1 Overview", " Financial Scorecard Mingming Li 2022-01-30 Chapter 1 Overview The goal of this project is to maximize the profit with acceptable default risks. We built a model to study key variables that might lead a customer to default; then, we referred to the rejection data to adjust the modelâ€™s accuracy. Based on the final model we created, we designed the scorecard, which measures the applicants in three dimensions, Persons Per Household, Name of Credit Card, Time at Job (months). The results showed that to keep the risk of default rate at 3.23%, our model can help the Bank accept 96% of applications, and to keep the acceptance rate at the original 75%, the model can minimize the default rate to 1.41%. We suggest the company use our model to assess credit card applications and set the score cutoff between 441 and 472 to lower the default risks while accepting more applications. Scorecard "],["initial-score-card.html", "Chapter 2 Initial Score Card 2.1 Exploratory Data Analysis 2.2 Variables Selection 2.3 Standardize Continuous Variables 2.4 Standardize Categorical Variables 2.5 Initial Logistic Regression Model and Model Selection 2.6 Evaluate the Initial Model - Training Data 2.7 Evaluate the Initial Model - Testing Data", " Chapter 2 Initial Score Card Dropping Division, Nationality, Age, and Number of Children for regulatory requirements accepts&lt;-subset(accepts, select=-c(DIV, CHILDREN, NAT, AGE)) rejects&lt;-subset(rejects, select=-c(DIV, CHILDREN, NAT, AGE)) accepts$good &lt;- abs(accepts$GB - 1) 2.1 Exploratory Data Analysis unique value for each variable print(as.data.frame(lapply(lapply(accepts,unique),length))) ## PERS_H TMADD TMJOB1 TEL NMBLOAN FINLOAN INCOME EC_CARD BUREAU LOCATION LOANS REGN CASH PRODUCT RESID ## 1 10 32 33 3 3 2 27 2 3 2 9 9 29 7 3 ## PROF CAR CARDS GB X_freq_ good ## 1 10 3 7 2 2 2 set.seed(12345) train_id &lt;- sample(seq_len(nrow(accepts)), size = floor(0.70*nrow(accepts))) train &lt;- accepts[train_id, ] test &lt;- accepts[-train_id, ] Variable Classification Categorical Variable Variable Level &lt; = 10 Variable Type is Character Continuous Variables Not Continuous col_unique&lt;-lapply(lapply(train,unique),length) catag_variable&lt;-names(col_unique[col_unique&lt;=10]) chara_type&lt;-lapply(train,typeof) chara_names&lt;-names(chara_type[chara_type==&quot;character&quot;]) catag_variable&lt;-unique(c(chara_names,catag_variable)) catag_variable&lt;-subset(catag_variable,!(catag_variable%in%c(&quot;good&quot;))) conti_variable&lt;-names(train) conti_variable&lt;-subset(conti_variable,!(conti_variable%in%catag_variable)) Factorize the categorical variables train[,catag_variable]=lapply(train[,catag_variable],as.factor) test[,catag_variable]=lapply(test[,catag_variable],as.factor) 2.2 Variables Selection key_variable Continuous Variables: Tenure, Income Categorical Variables: Person in the household, Card Name, EC Card Holder result_con &lt;- list() # Creating empty list to store all results # for(i in 1:length(conti_variable)){ result_con[[conti_variable[i]]] &lt;- smbinning(df = train, y = &quot;good&quot;, x = conti_variable[i]) } smbinning.sumiv.plot(iv_summary) key_variable&lt;-iv_summary$Char[iv_summary$IV&gt;=0.1&amp;is.na(iv_summary$IV)==FALSE] results&lt;-c(result_con) result_all_sig&lt;-results[key_variable] 2.3 Standardize Continuous Variables Bin continuous variables and Caclulate the WOE Add the Binned Variable and WOE to the original training dataset for(i in 1:2) { train &lt;- smbinning.gen(df = train, ivout = result_all_sig[[i]], chrname = paste(result_all_sig[[i]]$x, &quot;_bin&quot;, sep = &quot;&quot;)) } for (j in 1:2) { for (i in 1:nrow(train)) { bin_name &lt;- paste(result_all_sig[[j]]$x, &quot;_bin&quot;, sep = &quot;&quot;) bin &lt;- substr(train[[bin_name]][i], 2, 2) woe_name &lt;- paste(result_all_sig[[j]]$x, &quot;_WOE&quot;, sep = &quot;&quot;) if(bin == 0) { bin &lt;- dim(result_all_sig[[j]]$ivtable)[1] - 1 train[[woe_name]][i] &lt;- result_all_sig[[j]]$ivtable[bin, &quot;WoE&quot;] } else { train[[woe_name]][i] &lt;- result_all_sig[[j]]$ivtable[bin, &quot;WoE&quot;] } } } 2.4 Standardize Categorical Variables Calculate the WOE using the klaR package Add WOE to the original training dataset train$good&lt;-as.factor(train$good) woemodel &lt;- woe(good~., data = train, zeroadj=0.005, applyontrain = TRUE) ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## At least one empty cell (class x level) does exists. Zero adjustment applied! traindata &lt;- predict(woemodel, train, replace = TRUE) ## No woe model for variable(s): good train=cbind(train,traindata[,c(&quot;woe_CARDS&quot;,&quot;woe_PERS_H&quot;,&quot;woe_EC_CARD&quot;)]) ############################## mapping tables for the categorical woe ############################## cate1=unique(train[,c(&quot;CARDS&quot;,&quot;woe_CARDS&quot;)]) cate2=unique(train[,c(&quot;PERS_H&quot;,&quot;woe_PERS_H&quot;)]) cate3=unique(train[,c(&quot;EC_CARD&quot;,&quot;woe_EC_CARD&quot;)]) #################################################################################################### 2.5 Initial Logistic Regression Model and Model Selection train$X_freq_=as.numeric(as.character(train$X_freq_)) initial_score &lt;- glm(data = train, GB ~ TMJOB1_WOE + INCOME_WOE + woe_CARDS+woe_PERS_H+woe_EC_CARD , weights =X_freq_,family = &quot;binomial&quot;) summary(initial_score) ## ## Call: ## glm(formula = GB ~ TMJOB1_WOE + INCOME_WOE + woe_CARDS + woe_PERS_H + ## woe_EC_CARD, family = &quot;binomial&quot;, data = train, weights = X_freq_) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.4537 -1.3243 -0.1546 2.5085 3.2984 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.40252 0.03328 -102.231 &lt; 0.0000000000000002 *** ## TMJOB1_WOE -0.86482 0.07856 -11.009 &lt; 0.0000000000000002 *** ## INCOME_WOE -0.17260 0.11370 -1.518 0.129 ## woe_CARDS 0.98698 0.24951 3.956 0.0000763 *** ## woe_PERS_H 0.82881 0.08009 10.348 &lt; 0.0000000000000002 *** ## woe_EC_CARD -0.11756 0.27155 -0.433 0.665 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 9272.2 on 2099 degrees of freedom ## Residual deviance: 8812.9 on 2094 degrees of freedom ## AIC: 8824.9 ## ## Number of Fisher Scoring iterations: 5 # Variable Selected Logistic Regression initial_score_red &lt;- glm(data = train, GB ~ TMJOB1_WOE + woe_CARDS+woe_PERS_H , weights =X_freq_,family = &quot;binomial&quot;) summary(initial_score_red) ## ## Call: ## glm(formula = GB ~ TMJOB1_WOE + woe_CARDS + woe_PERS_H, family = &quot;binomial&quot;, ## data = train, weights = X_freq_) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.434 -1.359 -0.150 2.495 3.279 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.40238 0.03328 -102.25 &lt;0.0000000000000002 *** ## TMJOB1_WOE -0.88852 0.07713 -11.52 &lt;0.0000000000000002 *** ## woe_CARDS 1.01760 0.09591 10.61 &lt;0.0000000000000002 *** ## woe_PERS_H 0.84999 0.07905 10.75 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 9272.2 on 2099 degrees of freedom ## Residual deviance: 8815.2 on 2096 degrees of freedom ## AIC: 8823.2 ## ## Number of Fisher Scoring iterations: 5 2.6 Evaluate the Initial Model - Training Data ## where predictions have outliers train$pred&gt;=0.2 train$pred=predict(initial_score_red,data=train,type = &quot;response&quot;) train$GB&lt;-as.numeric(as.character(train$GB)) train$good&lt;-as.numeric(as.character(train$good)) smbinning.metrics(dataset = train, prediction = &quot;pred&quot;, actualclass = &quot;GB&quot;, report = 1) ## ## Overall Performance Metrics ## -------------------------------------------------- ## KS : 0.2686 (Unpredictive) ## AUC : 0.6847 (Poor) ## ## Classification Matrix ## -------------------------------------------------- ## Cutoff (&gt;=) : 0.0335 (Optimal) ## True Positives (TP) : 704 ## False Positives (FP) : 423 ## False Negatives (FN) : 345 ## True Negatives (TN) : 628 ## Total Positives (P) : 1049 ## Total Negatives (N) : 1051 ## ## Business/Performance Metrics ## -------------------------------------------------- ## %Records&gt;=Cutoff : 0.5367 ## Good Rate : 0.6247 (Vs 0.4995 Overall) ## Bad Rate : 0.3753 (Vs 0.5005 Overall) ## Accuracy (ACC) : 0.6343 ## Sensitivity (TPR) : 0.6711 ## False Neg. Rate (FNR) : 0.3289 ## False Pos. Rate (FPR) : 0.4025 ## Specificity (TNR) : 0.5975 ## Precision (PPV) : 0.6247 ## False Discovery Rate : 0.3753 ## False Omision Rate : 0.3546 ## Inv. Precision (NPV) : 0.6454 ## ## Note: 0 rows deleted due to missing data. smbinning.metrics(dataset = train[train$pred&lt;=0.2,], prediction = &quot;pred&quot;, actualclass = &quot;GB&quot;, report = 0, plot = &quot;ks&quot;) smbinning.metrics(dataset = train, prediction = &quot;pred&quot;, actualclass = &quot;GB&quot;, report = 0, plot = &quot;auc&quot;) pred&lt;-prediction(fitted(initial_score_red),factor(train$GB)) perf&lt;-performance(pred,measure=&quot;tpr&quot;,x.measure=&quot;fpr&quot;) plot(perf,lwd=3,colorsize=TRUE,colorkey=TRUE,colorsize.palette=rev(gray.colors(256))) KS&lt;-max(perf@y.values[[1]]-perf@x.values[[1]]) ## 0.03351922 cutoffAtKS&lt;-unlist(perf@alpha.values)[which.max(perf@y.values[[1]]-perf@x.values[[1]])] print(c(KS,cutoffAtKS)) ## [1] 0.26864151 0.03351922 2.7 Evaluate the Initial Model - Testing Data for(i in 1:2) { test &lt;- smbinning.gen(df = test, ivout = result_all_sig[[i]], chrname = paste(result_all_sig[[i]]$x, &quot;_bin&quot;, sep = &quot;&quot;)) } for (j in 1:2) { for (i in 1:nrow(test)) { bin_name &lt;- paste(result_all_sig[[j]]$x, &quot;_bin&quot;, sep = &quot;&quot;) bin &lt;- substr(test[[bin_name]][i], 2, 2) woe_name &lt;- paste(result_all_sig[[j]]$x, &quot;_WOE&quot;, sep = &quot;&quot;) if(bin == 0) { bin &lt;- dim(result_all_sig[[j]]$ivtable)[1] - 1 test[[woe_name]][i] &lt;- result_all_sig[[j]]$ivtable[bin, &quot;WoE&quot;] } else { test[[woe_name]][i] &lt;- result_all_sig[[j]]$ivtable[bin, &quot;WoE&quot;] } } } test$good&lt;-as.factor(test$good) ########## categorical #################################### test&lt;-merge(test,cate1,by=&quot;CARDS&quot;,all.x = TRUE) test&lt;-merge(test,cate2,by=&quot;PERS_H&quot;,all.x = TRUE) ########## categorical #################################### test$good=as.numeric(as.character(test$good)) test$GB=as.numeric(as.character(test$GB)) test$X_freq_=as.numeric(as.character(test$X_freq_)) test$pred &lt;- predict(initial_score_red, newdata=test, type=&#39;response&#39;) smbinning.metrics(dataset = test, prediction = &quot;pred&quot;, actualclass = &quot;GB&quot;, report = 1) ## ## Overall Performance Metrics ## -------------------------------------------------- ## KS : 0.2979 (Unpredictive) ## AUC : 0.6892 (Poor) ## ## Classification Matrix ## -------------------------------------------------- ## Cutoff (&gt;=) : 0.0468 (Optimal) ## True Positives (TP) : 234 ## False Positives (FP) : 99 ## False Negatives (FN) : 217 ## True Negatives (TN) : 349 ## Total Positives (P) : 451 ## Total Negatives (N) : 448 ## ## Business/Performance Metrics ## -------------------------------------------------- ## %Records&gt;=Cutoff : 0.3704 ## Good Rate : 0.7027 (Vs 0.5017 Overall) ## Bad Rate : 0.2973 (Vs 0.4983 Overall) ## Accuracy (ACC) : 0.6485 ## Sensitivity (TPR) : 0.5188 ## False Neg. Rate (FNR) : 0.4812 ## False Pos. Rate (FPR) : 0.2210 ## Specificity (TNR) : 0.7790 ## Precision (PPV) : 0.7027 ## False Discovery Rate : 0.2973 ## False Omision Rate : 0.3834 ## Inv. Precision (NPV) : 0.6166 ## ## Note: 1 rows deleted due to missing data. smbinning.metrics(dataset = test[test$pred&lt;=0.2,], prediction = &quot;pred&quot;, actualclass = &quot;GB&quot;, report = 0, plot = &quot;ks&quot;) smbinning.metrics(dataset = test, prediction = &quot;pred&quot;, actualclass = &quot;GB&quot;, report = 0, plot = &quot;auc&quot;) "],["reject-inference.html", "Chapter 3 Reject Inference 3.1 Data Cleaning 3.2 Predicted Scores 3.3 Predicted Default Probability", " Chapter 3 Reject Inference 3.1 Data Cleaning rejects&lt;-read.csv(&quot;/Users/mingming/Documents/Financial Analysis/Homework1_FA/rejected_customers.csv&quot;) accepts$good &lt;- abs(accepts$GB - 1) catag_variable_new=names(rejects)[names(rejects)%in%catag_variable] rejects[,catag_variable_new]=lapply(rejects[,catag_variable_new],as.factor) ################# unique(train[,c(&quot;TMJOB1_bin&quot;,&quot;TMJOB1_WOE&quot;)]) ## TMJOB1_bin TMJOB1_WOE ## 2190 02 &lt;= 144 -0.0402 ## 51 03 &gt; 144 1.0757 ## 2712 01 &lt;= 15 -0.5484 rejects$TMJOB1_bin&lt;-rep(&quot;&quot;,nrow(rejects)) rejects$TMJOB1_bin[rejects$TMJOB1&lt;=15]=&quot;&lt;= 15&quot; rejects$TMJOB1_bin[rejects$TMJOB1&lt;=144&amp;rejects$TMJOB1&gt;15]=&quot;&lt;= 144&quot; rejects$TMJOB1_bin[rejects$TMJOB1&gt;144]=&quot;&gt;144&quot; rejects$TMJOB1_WOE&lt;-rep(0,nrow(rejects)) rejects$TMJOB1_WOE[rejects$TMJOB1&lt;=15]=-0.5484 rejects$TMJOB1_WOE[rejects$TMJOB1&lt;=144&amp;rejects$TMJOB1&gt;15]=-0.0402 rejects$TMJOB1_WOE[rejects$TMJOB1&gt;144]=1.0757 rejects&lt;-merge(rejects,cate1,by=&quot;CARDS&quot;,all.x = TRUE) rejects&lt;-merge(rejects,cate2,by=&quot;PERS_H&quot;,all.x = TRUE) as.data.frame(lapply(lapply(rejects,is.na),sum)&gt;0) ## lapply(lapply(rejects, is.na), sum) &gt; 0 ## PERS_H FALSE ## CARDS FALSE ## CHILDREN FALSE ## AGE FALSE ## TMADD FALSE ## TMJOB1 FALSE ## TEL FALSE ## NMBLOAN FALSE ## FINLOAN FALSE ## INCOME FALSE ## EC_CARD FALSE ## BUREAU FALSE ## LOCATION FALSE ## LOANS FALSE ## REGN FALSE ## DIV FALSE ## CASH FALSE ## PRODUCT FALSE ## RESID FALSE ## NAT FALSE ## PROF FALSE ## CAR FALSE ## TMJOB1_bin FALSE ## TMJOB1_WOE FALSE ## woe_CARDS TRUE ## woe_PERS_H TRUE rejects[is.na(rejects$woe_PERS_H),] ### PERS_H fail out the range of the accepted data ## PERS_H CARDS CHILDREN AGE TMADD TMJOB1 TEL NMBLOAN FINLOAN INCOME EC_CARD BUREAU LOCATION ## 1500 11 no credit cards 9 56 120 12 2 0 0 1600 0 3 1 ## LOANS REGN DIV CASH PRODUCT RESID NAT PROF CAR TMJOB1_bin TMJOB1_WOE ## 1500 0 5 1 1700 Radio, TV, Hifi Turkish Others Without Vehicle &lt;= 15 -0.5484 ## woe_CARDS woe_PERS_H ## 1500 0.2268594 NA ##impute rejects$woe_PERS_H[is.na(rejects$woe_PERS_H)]=5.3002221 rejects[is.na(rejects$woe_CARDS),] ## VISA Citibank is not one category in the accept data ## PERS_H CARDS CHILDREN AGE TMADD TMJOB1 TEL NMBLOAN FINLOAN INCOME EC_CARD BUREAU LOCATION ## 403 1 VISA Citibank 0 22 264 42 2 2 1 0 0 1 1 ## 1402 4 VISA Citibank 2 36 6 216 2 0 0 0 0 1 1 ## LOANS REGN DIV CASH PRODUCT RESID NAT PROF CAR TMJOB1_bin ## 403 2 3 1 1500 Radio, TV, Hifi Lease German Others Without Vehicle &lt;= 144 ## 1402 5 2 1 2500 Radio, TV, Hifi Lease German Military Service Car &gt;144 ## TMJOB1_WOE woe_CARDS woe_PERS_H ## 403 -0.0402 NA 0.4926674 ## 1402 1.0757 NA -0.2655746 ##impute as the value of VISA Others rejects$woe_CARDS[is.na(rejects$woe_CARDS)]=train$woe_CARDS[train$CARDS==&quot;VISA Others&quot;] as.data.frame(lapply(lapply(rejects,is.na),sum)&gt;0) ## lapply(lapply(rejects, is.na), sum) &gt; 0 ## PERS_H FALSE ## CARDS FALSE ## CHILDREN FALSE ## AGE FALSE ## TMADD FALSE ## TMJOB1 FALSE ## TEL FALSE ## NMBLOAN FALSE ## FINLOAN FALSE ## INCOME FALSE ## EC_CARD FALSE ## BUREAU FALSE ## LOCATION FALSE ## LOANS FALSE ## REGN FALSE ## DIV FALSE ## CASH FALSE ## PRODUCT FALSE ## RESID FALSE ## NAT FALSE ## PROF FALSE ## CAR FALSE ## TMJOB1_bin FALSE ## TMJOB1_WOE FALSE ## woe_CARDS FALSE ## woe_PERS_H FALSE 3.2 Predicted Scores pdo &lt;- 20 score &lt;- 500 odds &lt;- 50 fact &lt;- pdo/log(2) os &lt;- score - fact*log(odds) var_names &lt;- names(initial_score_red$coefficients[-1]) for(i in var_names) { beta &lt;- initial_score_red$coefficients[i] beta0 &lt;- initial_score_red$coefficients[&quot;(Intercept)&quot;] nvar &lt;- length(var_names) WOE_var &lt;- rejects[[i]] points_name &lt;- paste(i, &quot;points&quot;, sep=&quot;&quot;) rejects[[points_name]] &lt;- -(WOE_var*(beta) + (beta0/nvar))*fact + os/nvar } colini &lt;- (ncol(rejects)-nvar + 1) colend &lt;- ncol(rejects) rejects$Score &lt;- rowSums(rejects[, colini:colend]) 3.3 Predicted Default Probability rejects$pred &lt;- predict(initial_score_red, newdata=rejects, type=&#39;response&#39;) rejects$GB &lt;- as.numeric(rejects$pred &gt; 0.03351922) rejects$good &lt;- abs(rejects$GB - 1) Data oversampling and weight calculation pop_g &lt;- 9677 pop_b &lt;- 323 sam_g &lt;- 1500 sam_b &lt;- 1500 pop_sam_gb_ratio &lt;- (pop_g/pop_b)/(sam_g/sam_b) pop_a &lt;- 0.75 pop_r &lt;- 0.25 sam_a &lt;- 30 sam_r &lt;- 15 pop_sam_ar_ratio &lt;- (pop_a/pop_r)/(sam_a/sam_r) weight_rb &lt;- 1 weight_rg &lt;- pop_sam_gb_ratio weight_ab &lt;- pop_sam_ar_ratio weight_ag &lt;- pop_sam_ar_ratio*pop_sam_gb_ratio accepts$weight_ar &lt;- ifelse(accepts$GB == 1, weight_ab, weight_ag) rejects$weight_ar &lt;- ifelse(rejects$GB == 1, weight_rb, weight_rg) accepts=subset(accepts,select=-c(X_freq_)) comb_hard &lt;- rbind(accepts, rejects[,names(accepts)]) # New Combined Data Set # # Below can be used to see if there is any missing value # lapply(lapply(accepts,is.na),sum)&gt;0 # lapply(lapply(rejects,is.na),sum)&gt;0 # lapply(lapply(comb_hard,is.na),sum)&gt;0 "],["build-final-scorecard-model.html", "Chapter 4 Build Final Scorecard Model 4.1 Build the logistic regression and variable selection 4.2 Evaluate the Initial Model 4.3 Final Scorecard 4.4 Score distribution 4.5 Plotting Default, Acceptance, &amp; Profit By Score", " Chapter 4 Build Final Scorecard Model Data Binning and WOE calculation comb &lt;- comb_hard # Select which data set you want to use from above techniques # set.seed(12345) train_id &lt;- sample(seq_len(nrow(comb)), size = floor(0.7*nrow(comb))) train &lt;- comb[train_id, ] test &lt;- comb[-train_id, ] ## categorical variable -&gt; level&lt;10, or col_unique&lt;-lapply(lapply(train,unique),length) catag_variable&lt;-names(col_unique[col_unique&lt;=10]) #2. type=character chara_type&lt;-lapply(train,typeof) chara_names&lt;-names(chara_type[chara_type==&quot;character&quot;]) catag_variable&lt;-unique(c(chara_names,catag_variable)) catag_variable&lt;-subset(catag_variable,!(catag_variable%in%c(&quot;good&quot;))) #continuous variable (not categorical) conti_variable&lt;-names(train) conti_variable&lt;-subset(conti_variable,!(conti_variable%in%catag_variable)) # factorize both train and the test train[,catag_variable]=lapply(train[,catag_variable],as.factor) #str(train) test[,catag_variable]=lapply(test[,catag_variable],as.factor) #str(test) # Binning continuous variable result_con &lt;- list() for(i in 1:length(conti_variable)){ result_con[[conti_variable[i]]] &lt;- smbinning(df = train, y = &quot;good&quot;, x = conti_variable[i]) } smbinning.sumiv.plot(iv_summary) key_variable&lt;-iv_summary$Char[iv_summary$IV&gt;=0.1&amp;is.na(iv_summary$IV)==FALSE] results&lt;-c(result_con) result_all_sig&lt;-results[key_variable] for(i in c(1,4)) { train &lt;- smbinning.gen(df = train, ivout = result_all_sig[[i]], chrname = paste(result_all_sig[[i]]$x, &quot;_bin&quot;, sep = &quot;&quot;)) } for (j in c(1,4)) { for (i in 1:nrow(train)) { bin_name &lt;- paste(result_all_sig[[j]]$x, &quot;_bin&quot;, sep = &quot;&quot;) bin &lt;- substr(train[[bin_name]][i], 2, 2) woe_name &lt;- paste(result_all_sig[[j]]$x, &quot;_WOE&quot;, sep = &quot;&quot;) if(bin == 0) { bin &lt;- dim(result_all_sig[[j]]$ivtable)[1] - 1 train[[woe_name]][i] &lt;- result_all_sig[[j]]$ivtable[bin, &quot;WoE&quot;] } else { train[[woe_name]][i] &lt;- result_all_sig[[j]]$ivtable[bin, &quot;WoE&quot;] } } } #Below is useful for checking data cleaning process #lapply(lapply(train[,key_variable[c(2,3,5)]],is.na),sum) # calculate the WOE train$good&lt;-as.factor(train$good) woemodel &lt;- woe(good~., data = train, zeroadj=0.005, applyontrain = TRUE) ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## At least one empty cell (class x level) does exists. Zero adjustment applied! ## apply woes traindata &lt;- predict(woemodel, train, replace = TRUE) ## No woe model for variable(s): good #str(traindata) train=cbind(train,traindata[,c(&quot;woe_CARDS&quot;,&quot;woe_PERS_H&quot;,&quot;woe_EC_CARD&quot;)]) ############################## mapling table for the categorical woe ############################## cate1=unique(train[,c(&quot;CARDS&quot;,&quot;woe_CARDS&quot;)]) cate2=unique(train[,c(&quot;PERS_H&quot;,&quot;woe_PERS_H&quot;)]) cate3=unique(train[,c(&quot;EC_CARD&quot;,&quot;woe_EC_CARD&quot;)]) #################################################################################################### train$weight_ar&lt;-as.numeric(as.character(train$weight_ar)) 4.1 Build the logistic regression and variable selection initial_score &lt;- glm(data = train, GB ~ TMJOB1_WOE + INCOME_WOE+ woe_CARDS+woe_PERS_H+woe_EC_CARD , weights =weight_ar,family = &quot;binomial&quot;) summary(initial_score) ## ## Call: ## glm(formula = GB ~ TMJOB1_WOE + INCOME_WOE + woe_CARDS + woe_PERS_H + ## woe_EC_CARD, family = &quot;binomial&quot;, data = train, weights = weight_ar) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -5.115 -1.151 1.997 2.662 4.427 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.19686 0.02395 -133.491 &lt; 0.0000000000000002 *** ## TMJOB1_WOE -0.87136 0.03355 -25.970 &lt; 0.0000000000000002 *** ## INCOME_WOE -0.20747 0.05761 -3.601 0.000317 *** ## woe_CARDS 1.04236 0.12078 8.630 &lt; 0.0000000000000002 *** ## woe_PERS_H 0.79047 0.03708 21.318 &lt; 0.0000000000000002 *** ## woe_EC_CARD -0.18214 0.13127 -1.388 0.165270 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 19394 on 3149 degrees of freedom ## Residual deviance: 17138 on 3144 degrees of freedom ## AIC: 20286 ## ## Number of Fisher Scoring iterations: 6 Variable Selected Logistic Regression initial_score_red &lt;- glm(data = train, GB ~ TMJOB1_WOE + woe_CARDS+woe_PERS_H , weights =weight_ar,family = &quot;binomial&quot;) summary(initial_score_red) ## ## Call: ## glm(formula = GB ~ TMJOB1_WOE + woe_CARDS + woe_PERS_H, family = &quot;binomial&quot;, ## data = train, weights = weight_ar) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.956 -1.162 1.992 2.663 4.365 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.19627 0.02391 -133.66 &lt;0.0000000000000002 *** ## TMJOB1_WOE -0.89123 0.03301 -27.00 &lt;0.0000000000000002 *** ## woe_CARDS 1.02451 0.04100 24.99 &lt;0.0000000000000002 *** ## woe_PERS_H 0.80044 0.03724 21.50 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 19394 on 3149 degrees of freedom ## Residual deviance: 17151 on 3146 degrees of freedom ## AIC: 20293 ## ## Number of Fisher Scoring iterations: 6 4.2 Evaluate the Initial Model Training Data KS - &gt; best cut off 0.04327352 ROC train$pred=predict(initial_score_red,data=train,type = &quot;response&quot;) #train[is.na(train$weight_ar),] train$GB&lt;-as.numeric(as.character(train$GB)) train$good&lt;-as.numeric(as.character(train$good)) smbinning.metrics(dataset = train, prediction = &quot;pred&quot;, actualclass = &quot;GB&quot;, report = 1) ## ## Overall Performance Metrics ## -------------------------------------------------- ## KS : 0.4908 (Good) ## AUC : 0.7948 (Fair) ## ## Classification Matrix ## -------------------------------------------------- ## Cutoff (&gt;=) : 0.0433 (Optimal) ## True Positives (TP) : 1345 ## False Positives (FP) : 380 ## False Negatives (FN) : 415 ## True Negatives (TN) : 1010 ## Total Positives (P) : 1760 ## Total Negatives (N) : 1390 ## ## Business/Performance Metrics ## -------------------------------------------------- ## %Records&gt;=Cutoff : 0.5476 ## Good Rate : 0.7797 (Vs 0.5587 Overall) ## Bad Rate : 0.2203 (Vs 0.4413 Overall) ## Accuracy (ACC) : 0.7476 ## Sensitivity (TPR) : 0.7642 ## False Neg. Rate (FNR) : 0.2358 ## False Pos. Rate (FPR) : 0.2734 ## Specificity (TNR) : 0.7266 ## Precision (PPV) : 0.7797 ## False Discovery Rate : 0.2203 ## False Omision Rate : 0.2912 ## Inv. Precision (NPV) : 0.7088 ## ## Note: 0 rows deleted due to missing data. smbinning.metrics(dataset = train[train$pred&lt;=0.4,], prediction = &quot;pred&quot;, actualclass = &quot;GB&quot;, report = 0, plot = &quot;ks&quot;) smbinning.metrics(dataset = train, prediction = &quot;pred&quot;, actualclass = &quot;GB&quot;, report = 0, plot = &quot;auc&quot;) pred&lt;-prediction(fitted(initial_score_red),factor(train$GB)) perf&lt;-performance(pred,measure=&quot;tpr&quot;,x.measure=&quot;fpr&quot;) plot(perf,lwd=3,colorsize=TRUE,colorkey=TRUE,colorsize.palette=rev(gray.colors(256))) KS&lt;-max(perf@y.values[[1]]-perf@x.values[[1]]) cutoffAtKS&lt;-unlist(perf@alpha.values)[which.max(perf@y.values[[1]]-perf@x.values[[1]])] print(c(KS,cutoffAtKS)) ## [1] 0.49082325 0.04327352 Testing Data test &lt;- comb[-train_id, ] test[,catag_variable]=lapply(test[,catag_variable],as.factor) str(test) ## &#39;data.frame&#39;: 1350 obs. of 21 variables: ## $ PERS_H : Factor w/ 9 levels &quot;1&quot;,&quot;10&quot;,&quot;2&quot;,&quot;3&quot;,..: 3 3 1 3 3 3 3 3 3 1 ... ## $ TMADD : int 3 60 72 168 192 240 264 288 360 999 ... ## $ TMJOB1 : int 999 999 999 999 999 999 999 999 999 999 ... ## $ TEL : Factor w/ 3 levels &quot;0&quot;,&quot;1&quot;,&quot;2&quot;: 3 3 3 3 2 2 3 3 3 3 ... ## $ NMBLOAN : Factor w/ 3 levels &quot;0&quot;,&quot;1&quot;,&quot;2&quot;: 1 3 3 1 1 1 3 1 1 3 ... ## $ FINLOAN : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 1 1 1 2 1 2 2 ... ## $ INCOME : int 1000 2900 2300 0 0 2100 0 0 3000 0 ... ## $ EC_CARD : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 1 1 1 2 1 2 2 1 2 ... ## $ BUREAU : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 1 1 1 3 1 1 1 3 1 ... ## $ LOCATION : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ LOANS : Factor w/ 11 levels &quot;0&quot;,&quot;1&quot;,&quot;10&quot;,&quot;2&quot;,..: 4 2 2 2 1 2 2 2 1 2 ... ## $ REGN : Factor w/ 9 levels &quot;0&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 2 2 1 1 1 1 2 1 3 1 ... ## $ CASH : int 1300 900 1100 1900 1100 8000 1400 800 7000 3000 ... ## $ PRODUCT : Factor w/ 9 levels &quot;&quot;,&quot;Cars&quot;,&quot;Dept. Store or Mail&quot;,..: 5 5 8 3 5 2 8 3 5 5 ... ## $ RESID : Factor w/ 3 levels &quot;&quot;,&quot;Lease&quot;,&quot;Owner&quot;: 2 3 2 2 2 2 2 2 3 2 ... ## $ PROF : Factor w/ 14 levels &quot;&quot;,&quot;Chemical Industr&quot;,..: 8 8 8 8 3 8 3 8 8 8 ... ## $ CAR : Factor w/ 4 levels &quot;Car&quot;,&quot;Car and Motor bi&quot;,..: 1 1 4 1 1 1 1 1 1 4 ... ## $ CARDS : Factor w/ 6 levels &quot;Cheque card&quot;,..: 1 3 3 2 1 3 1 1 3 1 ... ## $ GB : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ good : num 1 1 1 1 1 1 1 1 1 1 ... ## $ weight_ar: Factor w/ 4 levels &quot;1&quot;,&quot;1.5&quot;,&quot;29.9597523219814&quot;,..: 4 4 4 4 4 4 4 4 4 4 ... for(i in 1:1) { test &lt;- smbinning.gen(df = test, ivout = result_all_sig[[i]], chrname = paste(result_all_sig[[i]]$x, &quot;_bin&quot;, sep = &quot;&quot;)) } for (j in 1:1) { for (i in 1:nrow(test)) { bin_name &lt;- paste(result_all_sig[[j]]$x, &quot;_bin&quot;, sep = &quot;&quot;) bin &lt;- substr(test[[bin_name]][i], 2, 2) woe_name &lt;- paste(result_all_sig[[j]]$x, &quot;_WOE&quot;, sep = &quot;&quot;) if(bin == 0) { bin &lt;- dim(result_all_sig[[j]]$ivtable)[1] - 1 test[[woe_name]][i] &lt;- result_all_sig[[j]]$ivtable[bin, &quot;WoE&quot;] } else { test[[woe_name]][i] &lt;- result_all_sig[[j]]$ivtable[bin, &quot;WoE&quot;] } } } test$good&lt;-as.factor(test$good) ########## categorical #################################### test&lt;-merge(test,cate1,by=&quot;CARDS&quot;,all.x = TRUE) test&lt;-merge(test,cate2,by=&quot;PERS_H&quot;,all.x = TRUE) ########## categorical #################################### test$good=as.numeric(as.character(test$good)) test$GB=as.numeric(as.character(test$GB)) test$pred &lt;- predict(initial_score_red, newdata=test, type=&#39;response&#39;) smbinning.metrics(dataset = test, prediction = &quot;pred&quot;, actualclass = &quot;GB&quot;, report = 1) ## ## Overall Performance Metrics ## -------------------------------------------------- ## KS : 0.4880 (Good) ## AUC : 0.7752 (Fair) ## ## Classification Matrix ## -------------------------------------------------- ## Cutoff (&gt;=) : 0.0333 (Optimal) ## True Positives (TP) : 608 ## False Positives (FP) : 181 ## False Negatives (FN) : 155 ## True Negatives (TN) : 405 ## Total Positives (P) : 763 ## Total Negatives (N) : 586 ## ## Business/Performance Metrics ## -------------------------------------------------- ## %Records&gt;=Cutoff : 0.5849 ## Good Rate : 0.7706 (Vs 0.5656 Overall) ## Bad Rate : 0.2294 (Vs 0.4344 Overall) ## Accuracy (ACC) : 0.7509 ## Sensitivity (TPR) : 0.7969 ## False Neg. Rate (FNR) : 0.2031 ## False Pos. Rate (FPR) : 0.3089 ## Specificity (TNR) : 0.6911 ## Precision (PPV) : 0.7706 ## False Discovery Rate : 0.2294 ## False Omision Rate : 0.2768 ## Inv. Precision (NPV) : 0.7232 ## ## Note: 1 rows deleted due to missing data. smbinning.metrics(dataset = test[test$pred&lt;=0.4,], prediction = &quot;pred&quot;, actualclass = &quot;GB&quot;, report = 1, plot = &quot;ks&quot;) ## ## Overall Performance Metrics ## -------------------------------------------------- ## KS : 0.4901 (Good) ## AUC : 0.7770 (Fair) ## ## Classification Matrix ## -------------------------------------------------- ## Cutoff (&gt;=) : 0.0333 (Optimal) ## True Positives (TP) : 607 ## False Positives (FP) : 179 ## False Negatives (FN) : 155 ## True Negatives (TN) : 405 ## Total Positives (P) : 762 ## Total Negatives (N) : 584 ## ## Business/Performance Metrics ## -------------------------------------------------- ## %Records&gt;=Cutoff : 0.5840 ## Good Rate : 0.7723 (Vs 0.5661 Overall) ## Bad Rate : 0.2277 (Vs 0.4339 Overall) ## Accuracy (ACC) : 0.7519 ## Sensitivity (TPR) : 0.7966 ## False Neg. Rate (FNR) : 0.2034 ## False Pos. Rate (FPR) : 0.3065 ## Specificity (TNR) : 0.6935 ## Precision (PPV) : 0.7723 ## False Discovery Rate : 0.2277 ## False Omision Rate : 0.2768 ## Inv. Precision (NPV) : 0.7232 ## ## Note: 1 rows deleted due to missing data. smbinning.metrics(dataset = test, prediction = &quot;pred&quot;, actualclass = &quot;GB&quot;, report = 0, plot = &quot;auc&quot;) 4.3 Final Scorecard final_score&lt;-initial_score_red pdo &lt;- 20 score &lt;- 500 odds &lt;- 50 fact &lt;- pdo/log(2) os &lt;- score - fact*log(odds) var_names &lt;- names(final_score$coefficients[-1]) for(i in var_names) { beta &lt;- final_score$coefficients[i] beta0 &lt;- final_score$coefficients[&quot;(Intercept)&quot;] nvar &lt;- length(var_names) WOE_var &lt;- train[[i]] points_name &lt;- paste(str_sub(i, end = -4), &quot;points&quot;, sep=&quot;&quot;) train[[points_name]] &lt;- -(WOE_var*(beta) + (beta0/nvar))*fact + os/nvar } colini &lt;- (ncol(train)-nvar + 1) colend &lt;- ncol(train) train$Score &lt;- rowSums(train[, colini:colend]) hist(train$Score, xlim=range(400,600), breaks = 30, main = &quot;Distribution of Scores&quot;, xlab = &quot;Score&quot;) for(i in var_names) { beta &lt;- final_score$coefficients[i] beta0 &lt;- final_score$coefficients[&quot;(Intercept)&quot;] nvar &lt;- length(var_names) WOE_var &lt;- test[[i]] points_name &lt;- paste(str_sub(i, end = -4), &quot;points&quot;, sep=&quot;&quot;) test[[points_name]] &lt;- -(WOE_var*(beta) + (beta0/nvar))*fact + os/nvar } colini &lt;- (ncol(test)-nvar + 1) colend &lt;- ncol(test) test$Score &lt;- rowSums(test[, colini:colend]) hist(test$Score, xlim=range(400,600), breaks = 30, main = &quot;Distribution of Test Scores&quot;, xlab = &quot;Score&quot;) accepts_scored_comb &lt;- rbind(train[,names(test)], test) hist(accepts_scored_comb$Score,xlim=range(400,600), breaks = 30, main = &quot;Distribution of Scores&quot;, xlab = &quot;Score&quot;) ################# Score Card ################### PERS_H_Score=unique(train[,c(&quot;PERS_H&quot;,&quot;woe_PERpoints&quot;)]) names(PERS_H_Score)=c(&quot;PERS_H&quot;,&quot;Point&quot;) CARDS_Score=unique(train[,c(&quot;CARDS&quot;,&quot;woe_CApoints&quot;)]) names(CARDS_Score)=c(&quot;CARDS&quot;,&quot;Point&quot;) TMJOB1_Score=unique(train[,c(&quot;TMJOB1_bin&quot;,&quot;TMJOB1_points&quot;)]) names(TMJOB1_Score)=c(&quot;TMJOB1&quot;,&quot;Point&quot;) ################# Score Card ################### Scorecard 4.4 Score distribution cutpoints &lt;- unique(quantile(accepts_scored_comb$Score, probs = seq(0,1,0.1),na.rm=TRUE)) accepts_scored_comb$Score.QBin &lt;- cut(accepts_scored_comb$Score, breaks=cutpoints, include.lowest=TRUE) Default.QBin.pop &lt;- round(table(accepts_scored_comb$Score.QBin, accepts_scored_comb$GB)[,2]/(table(accepts_scored_comb$Score.QBin, accepts_scored_comb$GB)[,2] + table(accepts_scored_comb$Score.QBin, accepts_scored_comb$GB)[,1]*weight_ag)*100,2) #print(Default.QBin.pop) barplot(Default.QBin.pop, main = &quot;Default Decile Plot&quot;, xlab = &quot;Deciles of Scorecard&quot;, ylab = &quot;Default Rate (%)&quot;, ylim = c(0,20), col = saturation(heat.colors, scalefac(0.8))(10)) abline(h = 3.23, lwd = 2, lty = &quot;dashed&quot;) text(9, 4.3, &quot;Current = 3.23%&quot;) 4.5 Plotting Default, Acceptance, &amp; Profit By Score def &lt;- NULL acc &lt;- NULL prof &lt;- NULL score &lt;- NULL cost &lt;- 52000 profit &lt;- 2000 for(i in min(floor(train$Score)):max(floor(train$Score))){ score[i - min(floor(train$Score)) + 1] &lt;- i def[i - min(floor(train$Score)) + 1] &lt;- 100*sum(train$GB[which(train$Score &gt;= i)])/(length(train$GB[which(train$Score &gt;= i &amp; train$GB == 1)]) + weight_ag*length(train$GB[which(train$Score &gt;= i &amp; train$GB == 0)])) acc[i - min(floor(train$Score)) + 1] &lt;- 100*(length(train$GB[which(train$Score &gt;= i &amp; train$GB == 1)]) + weight_ag*length(train$GB[which(train$Score &gt;= i &amp; train$GB == 0)]))/(length(train$GB[which(train$GB == 1)]) + weight_ag*length(train$GB[which(train$GB == 0)])) prof[i - min(floor(train$Score)) + 1] &lt;- length(train$GB[which(train$Score &gt;= i &amp; train$GB == 1)])*(-cost) + weight_ag*length(train$GB[which(train$Score &gt;= i &amp; train$GB == 0)])*profit } plot_data &lt;- data.frame(def, acc, prof, score) def_plot &lt;- xyplot(def ~ score, plot_data, type = &quot;l&quot; , lwd=2, col=&quot;red&quot;, ylab = &quot;Default Rate (%)&quot;, xlab = &quot;Score&quot;, xlim=c(400:600), main = &quot;Default Rate by Acceptance Across Score&quot;, panel = function(x, y,...) { panel.xyplot(x, y, ...) panel.abline(h = 3.23, col = &quot;red&quot;) }) acc_plot &lt;- xyplot(acc ~ score, plot_data, type = &quot;l&quot;, lwd=2, col=&quot;blue&quot;, ylab = &quot;Acceptance Rate (%)&quot;, xlim=c(400:600), panel = function(x, y,...) { panel.xyplot(x, y, ...) panel.abline(h = 75, col = &quot;blue&quot;) }) prof_plot &lt;- xyplot(prof/1000 ~ score, plot_data, type = &quot;l&quot; , lwd=2, col=&quot;green&quot;, ylab = &quot;Profit (Thousands $)&quot;, xlab = &quot;Score&quot;, xlim=c(400:600), main = &quot;Profit by Acceptance Across Score&quot; ) doubleYScale(def_plot, acc_plot, add.ylab2 = TRUE, use.style=FALSE) doubleYScale(prof_plot, acc_plot, add.ylab2 = TRUE, use.style=FALSE) as.data.frame(lapply(plot_data[abs(plot_data$acc-75)&lt;=4,],mean)) ## def acc prof score ## 1 0.9197601 71.56439 69093825 478 as.data.frame(plot_data[plot_data$score==472,]) ## def acc prof score ## 233 1.327788 80.91123 66672232 472 as.data.frame(lapply(plot_data[abs(plot_data$def-3.32)&lt;=0.03,],mean)) ## def acc prof score ## 1 NaN NaN NaN NaN as.data.frame(plot_data[plot_data$score==441,]) ## def acc prof score ## 202 2.221145 96.10569 49415842 441 "],["plot_ly.html", "Chapter 5 PLOT_LY", " Chapter 5 PLOT_LY newdata&lt;-plot_data[plot_data$score&gt;=400&amp;plot_data$score&lt;=600,] score&lt;-newdata$score def&lt;-newdata$def acc&lt;-newdata$acc prof&lt;-newdata$prof ay1 &lt;- list( title = &quot;Default Rate (%)&quot;, range = c(0, 10) ) ay2 &lt;- list( tickfont = list(), range = c(0, 100), overlaying = &quot;y&quot;, side = &quot;right&quot;, title = &quot;Acceptance Rate (%)&quot; ) fig &lt;- plot_ly() fig &lt;- fig %&gt;% add_lines(x = ~score, y = ~def, name = &quot;Default Rate (%)&quot;) fig &lt;- fig %&gt;% add_lines(x = ~score, y = ~acc, name = &quot;Acceptance Rate (%)&quot;, yaxis = &quot;y2&quot;) fig &lt;- fig %&gt;% layout( title = &quot;Default Rate by Acceptance Across Score&quot;, yaxis = ay1, yaxis2 = ay2, xaxis = list(title=&quot;Scorecard Value&quot;), legend = list(x = 1.2, y = 0.8) ) fig ay1 &lt;- list( title = &quot;Profit ($)&quot;, xlim=c(400:600), showline = FALSE, showgrid = FALSE ) ay2 &lt;- list( tickfont = list(), range = c(0, 100), overlaying = &quot;y&quot;, side = &quot;right&quot;, xlim=c(400:600), title = &quot;Acceptance Rate (%)&quot; ) fig &lt;- plot_ly() fig &lt;- fig %&gt;% add_lines(x = ~score, y = ~prof, name = &quot;Profit ($)&quot;) fig &lt;- fig %&gt;% add_lines(x = ~score, y = ~acc, name = &quot;Acceptance Rate (%)&quot;, yaxis = &quot;y2&quot;) fig &lt;- fig %&gt;% layout( title = &quot;Profit by Acceptance Across Score&quot;, yaxis = ay1, yaxis2 = ay2, xaxis = list(title=&quot;Scorecard Value&quot;), legend = list(x = 1.2, y = 0.8) ) fig "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
